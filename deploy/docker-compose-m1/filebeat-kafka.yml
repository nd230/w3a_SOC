filebeat.inputs:
- type: kafka
  enabled: true
  hosts: ["kafka:9092"]
  topics: ["weblogs"]
  group_id: "weblogs"

  json.keys_under_root: true
  json.add_error_key: true
  json.overwrite_keys: true

output.elasticsearch:
   hosts: ["elasticsearch:9200"]
   index: "weblog-%{+yyyy.MM.dd}"
setup.template.name: "filebeattest"
setup.template.pattern: "filebeattest-*"
processors:
  # kafka的消息会在message字段，通过该processor将json解析出来
  - decode_json_fields:
      fields: ["message"]
      process_array: true
      max_depth: 1
      target: ""
      overwrite_keys: true
      add_error_key: true
  # 下边这两个处理器根据自身需求设置    
  # 将json中start_time字段的时间放到@timestamp中
  - timestamp:
      # 格式化时间值 给 时间戳 
      field: start_time
      # 使用我国东八区时间  格式化log时间
      timezone: Asia/Shanghai
      layouts:
        # - '2006-01-02 15:04:05'
        - '2006-01-02 15:04:05.999'
      test:
        - '2019-06-22 16:33:51.111'
